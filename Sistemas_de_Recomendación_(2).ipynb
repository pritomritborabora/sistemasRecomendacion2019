{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sistemas de Recomendación (2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP0838wmjIs-",
        "colab_type": "text"
      },
      "source": [
        "# Sistemas de Recomendación de filtrado colaborativo\n",
        "\n",
        "En esta notebook, seguiremos con ***filtrado colaborativo***, una estrategia de recomendación basada en encontrar \"entidades\" similares. Existen dos alternativas:\n",
        "\n",
        "* ***User-User collaborative filtering.***. Solo considera el comportamiento previo de los usuarios (por ejemplo, sus ratings). La idea es sencilla. Si a dos usuarios $U_{1}$ y $U_{2}$ les interesaron los elementos $I_{a}$ y $I_{b}$, pero al usuario $U_{2}$ también le interesó el elemento $I_{c}$ que todavía no fue visto por $U_{1}$, se podría asumir que $U_{1}$ podría estar interesado en $I_{c}$.\n",
        "\n",
        "* ***Item-Item collaborative filtering.*** No considera las semejanzas entre los usuarios, sino que entre los elementos. En este contexto, las predicciones para un usuario $U$ nuevo que solo rateo pocos elementos, pueden ser fácilmente calculadas considerando los ratings que otros usuarios dieron a elementos similares.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://miro.medium.com/max/1920/1*QvhetbRjCr1vryTch_2HZQ.jpeg\" width=\"600\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhFVIWUUkI6W",
        "colab_type": "text"
      },
      "source": [
        "## User-user collaborative filtering\n",
        "\n",
        "Nuevamente vamos a usar un [dataset](https://raw.githubusercontent.com/tommantonela/sistemasRecomendacion2019/master/User-User%20Collaborative%20Filtering%20-%20movie-row.csv) de películas. \n",
        "Este dataset contiene los ratings que $25$ usuarios $u$ le asignaron a $100$ películas $m$. Si el usuario $u$ no le asignó rating a la película $m$, la celda correspondiente estará vacía. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp4chriIhly2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/tommantonela/sistemasRecomendacion2019/master/User-User%20Collaborative%20Filtering%20-%20movie-row.csv'\n",
        "df = pd.read_csv(url, sep=',',index_col=0)\n",
        "\n",
        "print(str(df.shape))\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykXh4Yf5nANL",
        "colab_type": "text"
      },
      "source": [
        "Dado que esta alternativa se basa en encontrar los usuarios más similares para luego realizar las recomendaciones, vamos a encontrar los vecinos más cercanos. Para ello, debemos definir:\n",
        "\n",
        "* La cantidad de vecinos a incorporar en la comparación.\n",
        "* Cómo se definirá la semejanza entre los usuarios.\n",
        "\n",
        "Con estas dos restricciones, vemos que tenemos un trade-off al decidir la cantidad de vecinos. Si el número de vecinos a seleccionar es demasiado bajo, lo más probable es que los usuarios no hayan rateado lo mismo, no pudiendo así proporcionar predicciones confiables. Por el contrario, si seleccionamos muchos vecinos, se incluirán vecinos \"no tan similares\" en la comparación, con gustos diferentes a los del usuario al que queremos darle las recomendaciones.\n",
        "  \n",
        "Existen [estudios](https://grouplens.org/site-content/uploads/evaluating-TOIS-20041.pdf) que determinaron que para la mayoría de las aplicaciones, considera entre $20$ y $30$ vecinos permite alcanzar los resultados óptimos.\n",
        "\n",
        "En lo que respecta a la semejanza, existen varias alternativas, como por ejemplo, distancia Euclídea (y variaciones), cosine similarity (y variaciones), pearson, entre otras. Por ahora, vamos a utilizar la correlación de pearson que se [demostró](https://grouplens.org/site-content/uploads/evaluating-TOIS-20041.pdf) que permite alcanzar buenos resultados para este tipo de recomendaciones.\n",
        "\n",
        "En resumen, para estas recomendaciones lo que vamos a hacer es:\n",
        "\n",
        "1. Partiendo de la matriz `user x movie`, calcular la semejanza entre todos los usuarios.\n",
        "2. Para cada usuario, filtrar los $k$ vecinos más similares.\n",
        "3. Predecir los ratings basados en los vecinos seleccionados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUbkTu4ho6no",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calcular correlación Pearson entre los usuarios\n",
        "df_corr = df.corr(method = 'pearson') # pandas ya permite hacer los cálculos de forma integrada\n",
        "df_corr.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5-tHU0xrWJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# buscamos los usuarios más similares/correlacionados, con el cuidado de eliminar a si mismo\n",
        "\n",
        "def findKNearestUsers(userCorrCol, k = 5):\n",
        "    return userCorrCol[userCorrCol.index != userCorrCol.name].nlargest(n = k).index.tolist()\n",
        "\n",
        "kNeighboors = df_corr.apply(lambda col: findKNearestUsers(col))\n",
        "kNeighboors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkUFWEO4reef",
        "colab_type": "text"
      },
      "source": [
        "### Predicción de los ratings\n",
        "\n",
        "Una vez que encontramos a los vecinos más similares, tenemos que predecir los ratings para los elementos que los usuarios no hayan todavía evaluado.\n",
        "\n",
        "Una forma sencilla de hacerlo es seleccionar a todos los vecinos que hayan rateado un elemento particular y calcular el promedio de dichos ratings. En este contexto, es preciso considerar que pueden existir distintos niveles de semejanza con los vecinos. Es así como sería deseable que los vecinos con mayor semejanza tengan un peso mayor en el cálculo del rating. Considerando un caso extremo, si solo existiesen $5$ usuarios compartiendo dos reviews de productos y uno de ellos no se encuentra relacionado con el usurio de interes, aún cuando pueda ser considerado un \"vecino\" sería deseable que tenga un peso mínimo en el cálculo del promedio. La forma de hacer esto es calcular un promedio ponderado donde $r$ representa los ratings de los vecinos del elemento de interés y $w$ la semejanza con el usuario de interés:\n",
        "\n",
        "$$\\frac{\\sum_{n=1}^{k} r_{n}w_{n}}{\\sum_{n=1}^{k} w_{n}}$$\n",
        "  \n",
        "El promedio tradicional es simplemente un promedio ponderado donde en todos los casos $w = 1$.\n",
        "\n",
        "Para simplificar los cálculos, se calcularán los ratings para todas las películas. En un escenario real, se haría solo para los ratings faltantes.\n",
        ".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvLGsHMVtpN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculatePredictionsUser(kNeighboors, user_correlations, df):\n",
        "    \n",
        "    def calculatePredictionsUserMovie(kNeighboors, user_correlations, movieRowRatings): \n",
        "        hasRatedMovie = ~np.isnan(movieRowRatings)\n",
        "        if(np.sum(hasRatedMovie) != 0): # only return value if there was at least one neighboor who also rated that movie\n",
        "            return np.dot(movieRowRatings.loc[hasRatedMovie], user_correlations.loc[hasRatedMovie])/np.sum(user_correlations[hasRatedMovie])\n",
        "        else:\n",
        "            return np.nan\n",
        "        \n",
        "    # looking at one user, apply function for each row = movie and predict rating for that movie\n",
        "    return df.apply(lambda movieRow: calculatePredictionsUserMovie(kNeighboors, user_correlations, movieRow[kNeighboors]), axis=1)\n",
        "    \n",
        "\n",
        "####### Starting process point\n",
        "# call function sending user's neighboors, neighboors similarity and movie ratings df     \n",
        "moviePredictions = df.apply(lambda userRatings: calculatePredictionsUser(kNeighboors[userRatings.name], \n",
        "                                                      df_corr[userRatings.name][kNeighboors[userRatings.name]],\n",
        "                                                      df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfI6zXOH2-yr",
        "colab_type": "text"
      },
      "source": [
        "Vamos a mirar las predicciones para un usuario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbzx3GuV3DJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moviePredictions['3867'].sort_values(ascending=False).head(10) # mirando las predicciones para un usuario random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfdAdP1luOzS",
        "colab_type": "text"
      },
      "source": [
        "La correlación de Pearson evalúa cuán linealmente dependientes son dos usuarios y no con qué intensidad. Esto implica que el rating entre los usuarios $U_{1} = [3,3,3,3,3]$ y $U_{2} = [4,4,4,4,4]$ y entre los usuarios $U_{3} = [2,2,2,2,2]$ y $U_{4} = [5,5,5,5,5]$ sería el mismo. Esto significa que no es posible promediar los ratings entre los usuarios debido a que la correlación no tiene en cuenta las variabilidades de las escalas entre los usuarios. \n",
        "\n",
        "Para tener en cuenta estas diferencias, es posible mejorar el promedio ponderando para considerar en cuánto se desvía la calificación dada por un vecino a un elemento del promedio de sus ratings. Finalmente, este valor debe ser incorporado al promedio del usuario de interés.\n",
        "\n",
        "$$\\bar{r_{u}} + \\frac{\\sum_{n=1}^{k} (r_{n} - \\bar{r_{n}})w_{n}}{\\sum_{n=1}^{k} w_{n}}$$\n",
        "\n",
        "En la implmentación, vamos a agregar dos parámetros extra:\n",
        "\n",
        "- `userMeanRating`. El rating promedio para el usuario particular.\n",
        "- `neighboorsMeanRating`. Promedio para todos los vecinos de un usuario particular."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ4XiTtmuSkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculatePredictionsUserNorm(kNeighboors, user_correlations, userMeanRating, neighboorsMeanRating, df):\n",
        "    \n",
        "    def calculatePredictionsUserMovieNorm(kNeighboors, user_correlations, userMeanRating, neighboorsMeanRating, movieRowRatings): \n",
        "        hasRatedMovie = ~np.isnan(movieRowRatings)\n",
        "        if(np.sum(hasRatedMovie) != 0): # only return value if there was at least one neighboor who also rated that movie\n",
        "            userRatingDeviation = movieRowRatings.loc[hasRatedMovie] - neighboorsMeanRating.loc[hasRatedMovie]\n",
        "            numerator = np.dot(userRatingDeviation, user_correlations.loc[hasRatedMovie])\n",
        "            return userMeanRating + numerator/np.sum(user_correlations[hasRatedMovie])\n",
        "        else:\n",
        "            return np.nan\n",
        "        \n",
        "    # looking at one user, apply function for each row = movie and predict rating for that movieprint\n",
        "    return df.apply(lambda movieRow: calculatePredictionsUserMovieNorm(kNeighboors, \n",
        "                                                                       user_correlations,\n",
        "                                                                       userMeanRating,\n",
        "                                                                       neighboorsMeanRating,\n",
        "                                                                       movieRow[kNeighboors]), axis=1)\n",
        "    \n",
        "\n",
        "####### Starting process point\n",
        "\n",
        "meanRatingPerUser = df.apply(np.mean)\n",
        "\n",
        "# call function sending user's neighboors, neighboors similarity and movie ratings df     \n",
        "moviePredictionsNorm = df.apply(lambda userRatings: \n",
        "                                          calculatePredictionsUserNorm(kNeighboors[userRatings.name], \n",
        "                                                      df_corr[userRatings.name][kNeighboors[userRatings.name]],\n",
        "                                                      np.mean(userRatings),                 \n",
        "                                                      meanRatingPerUser[kNeighboors[userRatings.name]],\n",
        "                                                      df))\n",
        "\n",
        "moviePredictionsNorm['3867'].sort_values(ascending=False).head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0dPOjqx5Ra5",
        "colab_type": "text"
      },
      "source": [
        "#### Comparemos los dos resultados obtenidos!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNyzo8Pyumul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finalMovie = pd.DataFrame()\n",
        "\n",
        "finalMovie['TitleNotNorm'] = moviePredictions['3867'].sort_values(ascending=False).head(10).index\n",
        "finalMovie['withoutNormalisation'] = moviePredictions['3867'].sort_values(ascending=False).head(10).values\n",
        "finalMovie['TitleNorm'] = moviePredictionsNorm['3867'].sort_values(ascending=False).head(10).index\n",
        "finalMovie['normalised'] = moviePredictionsNorm['3867'].sort_values(ascending=False).head(10).values\n",
        "finalMovie"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IpVVwt9uw1T",
        "colab_type": "text"
      },
      "source": [
        "### Algunos resultados raros...\n",
        "\n",
        "#### Predicciones mayores que el máximo de la escala?\n",
        "\n",
        "Al considerar puntajes normalizados, esto puede suceder si los usuarios que están siendo evaluados ya ratean las películas con un rating promedio elevado, y luego se le suma el desvío promedio de los vecinos, los cuales pueden o no estar en la misma escala.\n",
        "\n",
        "Por ejemplo:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oF4ozc4vC9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Promedio para el usuario 3867: ' + str(df[['3867']].apply(np.mean).values[0]))\n",
        "\n",
        "#########\n",
        "neighboors = kNeighboors['3867']\n",
        "weights = df_corr[['3867']].loc[neighboors]\n",
        "means = df[neighboors].apply(np.mean)\n",
        "ratings = df.loc[['1891: Star Wars: Episode V - The Empire Strikes Back (1980)']][neighboors]\n",
        "existingRatings = list(~(ratings.apply(np.isnan).values[0]))\n",
        "\n",
        "# weighted average deviation\n",
        "denominator = np.dot(ratings.loc[:,existingRatings] - means[existingRatings], weights[existingRatings]).tolist()[0]\n",
        "avgWeightedDeviation = (denominator/np.sum(weights[existingRatings])).values[0]\n",
        "\n",
        "print('Cuánto se desvía la media de los vencinos respecto a su propoio promedio ' +\n",
        "      'Star Wars: Episode V - The Empire Strike: ' + str(avgWeightedDeviation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoCZ0tgovPiQ",
        "colab_type": "text"
      },
      "source": [
        "Como puede observarse, el usuario `3687` no tiene un promedio alto, pero tiene vecinos que tienen promedios menores y Star Wars recibió ratings por encima de su propio promedio, lo que hizo que la predicción para `3687` superase el máximo de la escala.\n",
        "\n",
        "#### Las películas recomendadas no son las mismas?\n",
        "\n",
        "En los scores normalizados, Fargo aparece en el 4to lugar, mientras que no apareció al considerar los scores no normalizados. Qué puede haber pasado?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhdDDn5OvbbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Promedio para el usuario 3867: ' + str(df[['3867']].apply(np.mean).values[0]))\n",
        "\n",
        "#########\n",
        "neighboors = kNeighboors['3867']\n",
        "weights = df_corr[['3867']].loc[neighboors]\n",
        "means = df[neighboors].apply(np.mean)\n",
        "ratings = df.loc[['275: Fargo (1996)']][neighboors]\n",
        "existingRatings = list(~(ratings.apply(np.isnan).values[0]))\n",
        "\n",
        "print('Cuantos vecinos ratearon esta película: ' + str(np.sum(existingRatings)))\n",
        "print('Ratings de los vecinos: ' + str(ratings.loc[:,existingRatings].values[0][0]))\n",
        "\n",
        "weightedAvg = float((ratings.loc[:,existingRatings].values * weights[existingRatings]).iloc[:,0].values[0]/np.sum(weights[existingRatings]))\n",
        "print('--- Predicción final para el promedio ponderado \"normal\": ' + str(weightedAvg))\n",
        "\n",
        "# weighted average deviation\n",
        "denominator = np.dot(ratings.loc[:,existingRatings] - means[existingRatings], weights[existingRatings]).tolist()[0]\n",
        "avgWeightedDeviation = (denominator/np.sum(weights[existingRatings])).values[0]\n",
        "\n",
        "print('\\nDevío de los vecinos respecto a su propia media ' +\n",
        "      'Fargo (1996): ' + str(avgWeightedDeviation))\n",
        "print('--- Predicción final para el promedio ponderado normalizado: ' + str(df[['3867']].apply(np.mean).values[0] + avgWeightedDeviation))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svwXu4SEv4Md",
        "colab_type": "text"
      },
      "source": [
        "Estos cálculos fueron ligeramente más complicados dado que se quería comparar cómo las variantes de los promedios ponderados crearon diferentes ratings para una misma película. Como puede observarse, en la predicción normalizada solo se contaba con un vecino que había visto la película y este vecino la rateo con más de un punto por encima de su propio promedio. Entonces, la predicción era buena, pero no fue tan buena como el promedio ponderado normal, dado que solo fue buena para un único vecino, y no considerando la escala completa de rating.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8SylMxxwIrK",
        "colab_type": "text"
      },
      "source": [
        "### Resumiendo...\n",
        "\n",
        "User-User collaborative filtering ofrece una mejora respecto de los recomendadores no personalizados y basados en contenido. Ahora es posible realizar recomendaciones personalizadas, pero sin tener el desafío de cómo caracterizar y a los elementos. Sin embargo, todavía tiene algunos problemas:\n",
        "\n",
        "* No es escalable. \n",
        "* La semejanza entre los usuarios no se mantiene a lo largo del tiempo. \n",
        "* Dado que la mayoría de los usuarios solo ha etiquetado un reducido número de elementos, los datos son generalemente sparse.\n",
        "\n",
        "\n",
        "\n",
        "             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRWinvhNwiJg",
        "colab_type": "text"
      },
      "source": [
        "## Item-Item collaborative filtering\n",
        "\n",
        "El Item-Item CF ue creado por Amazon para resolver las problemáticas del `User-User`. En esta perfpectiva, como el nombre lo sugiere, se cambia el foco de los usuarios a los items. Entonces, en lugar de tener una matriz de semejanzas entre los usuarios, ahora se tiene una entre los elementos. Por ejemplo, cuando el usuario $u$ compró el elemento $i_{1}$, el cual era similar $i_{2}$, sería posible predecir que a $u$ le va a interesar $i_{2}$.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://miro.medium.com/max/1920/1*QvhetbRjCr1vryTch_2HZQ.jpeg\" width=\"600\">\n",
        "</p>\n",
        "\n",
        "Esta perspectiva ayuda a solucionar el problema de las pocas reviews provistas por unos pocos usuarios. Tener una gran cantidad de reviews hace que las relaciones entre los elementos no cambien demasiado, haciendo que las relaciones entre los elementos sean estables. Esto significa que la matriz de semejanzas no necesita ser recalculada seguido.\n",
        "\n",
        "Los pasos para realizar recomendaciones son:\n",
        "\n",
        "1. Obtener los datos.\n",
        "2. Crear la matriz de semejanzas correspondientes.\n",
        "3. Realizar las predicciones :D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfcai6HgxmSl",
        "colab_type": "text"
      },
      "source": [
        "Vamos a usar el mismo dataset que para user-user, solo que ahora, como el énfasis está puesto en los items, vamos a trasponerlo. Al igual que en el caso anterior, cada celda $c_{u,m}$ contiene el rating que el usario $u$ dió a la película $m$. Si el usuario no rateo la película, la celda correspondiente se encontrará vacía."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUIXfNnWxyoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_item = df.transpose()\n",
        "\n",
        "item_item"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEu1XYclyEjD",
        "colab_type": "text"
      },
      "source": [
        "### Crear la matriz de semejanzas\n",
        "\n",
        "Al igual que para las recomendaciones User-User, se tienen diversas posibildiades para elegir cómo calcular la semejanza entre los usuarios. En este contexto, [Herlocker et al (2002)](https://grouplens.org/site-content/uploads/evaluating-TOIS-20041.pdf) realizaron una evaluación experimental y encontraron que el cosine similarity permitía en alcanzar los mejores resultados.\n",
        "\n",
        "\n",
        "#### Calculando cosine similarity\n",
        "\n",
        "Un punto importante aquí es el cálculo del denominador. Aunque hacemos el producto de punto solo con valores existentes en ambas matrices, la norma de los vectores individuales considera todos los valores, y no solo las intersecciones entre `array_1` y `array_2`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HtxKdnUylLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cos_similarity(item1, item2):\n",
        "    item1Values = ~np.isnan(item1) # nos quedamos con los ratings existentes \n",
        "    item2Values = ~np.isnan(item2)\n",
        "    allValues = np.logical_and(item1Values,item2Values) # calculamos la intersección\n",
        "    return np.dot(item1[allValues], item2[allValues])/(np.linalg.norm(item1[item1Values]) * np.linalg.norm(item2[item2Values]))\n",
        "\n",
        "def pre_cos_similarity(item1, item_item):\n",
        "    return item_item.apply(lambda item2: cos_similarity(item1, item2))\n",
        "\n",
        "item_item_corr = item_item.apply(lambda item1: pre_cos_similarity(item1, item_item))\n",
        "item_item_corr.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Am8IZhmzpNw",
        "colab_type": "text"
      },
      "source": [
        "### Predicción de los ratings\n",
        "\n",
        "En este punto ya sabemos qué items son más similares a cuales. Esto ayudará a predecir un gran rating para dar pesos más altos a los ítems que son más similares a los que el usuario ya ha rateado.\n",
        "\n",
        "$$\\frac{\\sum_{n=1}^{k} r_{n}w_{n}}{\\sum_{n=1}^{k} w_{n}}$$\n",
        "  \n",
        "La diferencia con la recomendación User-User es que, al no haber más vecinos, el $n$ en la suma considera todos los ratings que el usuario $u$ haya realizado.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz-rham5z6zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictRating(userRatings, itemSimilarity):\n",
        "    userHasRating = ~np.isnan(userRatings)\n",
        "    return np.dot(userRatings[userHasRating], itemSimilarity[userHasRating])/np.sum(itemSimilarity[userHasRating])\n",
        "\n",
        "def pre_predictRating(userRatings, df_corr):\n",
        "    return item_item_corr.apply(lambda itemSimilarity: predictRating(userRatings, itemSimilarity))\n",
        "\n",
        "# hacemos las predicciones para cada usuario\n",
        "predictions = item_item.apply(lambda userRatings: pre_predictRating(userRatings, item_item_corr), axis=1)\n",
        "predictions.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf41DLX24Xvw",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, una vez que estimamos los ratings que los usuarios darían a las películas que todavía no ratearon, podemos hacer las recomendaciones!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSwQ9IqC4c1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# volvemos a nuestra matriz donde las columnas representan los usuarios y hacemos lo mismo que en el ejemplo anterior!\n",
        "user_predictions = predictions.transpose()\n",
        "\n",
        "x = [p[0] for p in np.argwhere(df['3867'].isnull().values).tolist()]\n",
        "\n",
        "df['3867'].index.values[x].tolist()\n",
        "\n",
        "user_predictions['3867'].loc[df['3867'].index.values[x].tolist()].sort_values(ascending=False).head(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAwLv1P8q25a",
        "colab_type": "text"
      },
      "source": [
        "Asimismo, también podemos comparar los ratings originales que dió el usuario con aquellos que fueron estimados en la recomendación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBQAJaK2rBG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = pd.DataFrame(df['3867'])\n",
        "a['new'] = user_predictions['3867']\n",
        "a[~a['3867'].isna()]\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Shqpyg0aH8",
        "colab_type": "text"
      },
      "source": [
        "Al igual que para la recomendación User-User es posible normalizar el promedio ponderado considerando el promedio de los elementos rateados. La ventaja es que permite considerar la variabilidad en la escala de los ratings de los diferentes usuarios. Para ello, normalizamos los ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_YyZx6H0b6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean normalise\n",
        "def subtractFromMean(col, meanCol):\n",
        "    result = np.array([np.nan] * col.shape[0])\n",
        "    isValidValue = ~np.isnan(col)\n",
        "    result[isValidValue] = col.values[isValidValue] - meanCol.values[isValidValue]\n",
        "    return result\n",
        "userMeanRatings = df.apply(np.mean, axis=1)\n",
        "df_ratings_norm = df.apply(lambda col: subtractFromMean(col, userMeanRatings)).transpose()\n",
        "\n",
        "print(item_item.shape)\n",
        "print(df_ratings_norm.shape)\n",
        "\n",
        "# similarity matrix\n",
        "item_item_corr_norm = item_item.apply(lambda item1: pre_cos_similarity(item1, df_ratings_norm))\n",
        "item_item_corr_norm.head()\n",
        "\n",
        "def replaceNegative(col):\n",
        "    col[col < 0] = 0\n",
        "    return col\n",
        "\n",
        "item_item_corr_norm = item_item_corr_norm.apply(replaceNegative)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaBV2BpQ4EJT",
        "colab_type": "text"
      },
      "source": [
        "Haciendo las recomendaciones!\n",
        "\n",
        "Al igual que hicimos en el caso anterior, qué películas se le recomendaría a los usuarios?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNju9zya4IdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recomendando pelis...\n",
        "predictions_norm = item_item.apply(lambda userRatings: pre_predictRating(userMeanRatings, item_item_corr_norm), axis=1)\n",
        "predictions_norm.head() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwDArWGtqD8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_predictions_norm = predictions_norm.transpose()\n",
        "\n",
        "x = [p[0] for p in np.argwhere(df['3867'].isnull().values).tolist()]\n",
        "\n",
        "df['3867'].index.values[x].tolist()\n",
        "\n",
        "user_predictions_norm['3867'].loc[df['3867'].index.values[x].tolist()].sort_values(ascending=False).head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRtXlU0YsXGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# comparar las predicciones con los ratings originales que había asignado el usuario\n",
        "a = pd.DataFrame(df['3867'])\n",
        "a['predictions_norm'] = user_predictions_norm['3867']\n",
        "a[~a['3867'].isna()]\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbESQTnn5G05",
        "colab_type": "text"
      },
      "source": [
        "#### Comparemos los dos resultados obtenidos!\n",
        "\n",
        "**Tarea!** Comparar los resultados de las recomendaciones como hicimos para el user-user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8Hr9r8b5bp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# comparación de resultados\n",
        "\n",
        "finalMovie = pd.DataFrame()\n",
        "\n",
        "finalMovie['TitleNotNorm'] = user_predictions['3867'].sort_values(ascending=False).head(10).index\n",
        "finalMovie['withoutNormalisation'] = user_predictions['3867'].sort_values(ascending=False).head(10).values\n",
        "finalMovie['TitleNorm'] = user_predictions_norm['3867'].sort_values(ascending=False).head(10).index\n",
        "finalMovie['normalised'] = user_predictions_norm['3867'].sort_values(ascending=False).head(10).values\n",
        "finalMovie"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drNOqQ6Q13S6",
        "colab_type": "text"
      },
      "source": [
        "### Resumiendo\n",
        "\n",
        "La recomendación Item-Item mejora a la User-User en términos de la complejidad computacional. Algunas consideraciones:\n",
        "\n",
        "1. Para el establecimiento de ratings estables es preciso que `number_users >> number_items`.\n",
        "2. Los mejores resultados se alcanzarán cuando los ratings sean estables, es decir, cuando los elementos tienen muchas evaluaciones.\n",
        "3. Falta de serendipia. Al basarse la recomendación en la semejanza de los elementos, en ocasiones puede ser difícil recomendar, items relevantes pero cuya semejanza con los ya conocimos es menor. \n"
      ]
    }
  ]
}